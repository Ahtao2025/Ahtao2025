{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ========== data info ============ #\n",
      "train validation data: (1000, 100)\n",
      "train validation label: (1000,)\n",
      "test data: (400, 100)\n",
      "test label: (400,)\n",
      "# ================================= #\n"
     ]
    }
   ],
   "source": [
    "from os import path as osp\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "def load_data():\n",
    "\n",
    "    data_dir = './data'\n",
    "    train_val_data_path = osp.join(data_dir, 'train_validation_data.npy')\n",
    "    train_val_label_path = osp.join(data_dir, 'train_validation_label.npy')\n",
    "    test_data_path = osp.join(data_dir, 'test_data.npy')\n",
    "    test_label_path = osp.join(data_dir, 'test_label.npy')\n",
    "\n",
    "    train_val_data = np.load(train_val_data_path)\n",
    "    train_val_label = np.load(train_val_label_path)\n",
    "    test_data = np.load(test_data_path)\n",
    "    test_label = np.load(test_label_path)\n",
    "    return train_val_data, train_val_label, test_data, test_label\n",
    "\n",
    "\n",
    "train_validation_data, train_validation_label, test_data, test_label = load_data()\n",
    "\n",
    "print(f'# ========== data info ============ #')\n",
    "print(f'train validation data: {train_validation_data.shape}')\n",
    "print(f'train validation label: {train_validation_label.shape}')\n",
    "print(f'test data: {test_data.shape}')\n",
    "print(f'test label: {test_label.shape}')\n",
    "print(f'# ================================= #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split for K-fold Cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def train_validation_split(K, train_val_data, train_val_label):\n",
    "\n",
    "    # TODO: ==========================\n",
    "    # Initialize lists to store the results for each fold\n",
    "    train_datas, train_labels, val_datas, val_labels = [], [], [], []\n",
    "\n",
    "    # Perform K-fold cross-validation\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in kf.split(train_val_data):\n",
    "        # Splitting data and labels based on indices\n",
    "        X_train, X_val = train_val_data[train_index], train_val_data[val_index]\n",
    "        y_train, y_val = train_val_label[train_index], train_val_label[val_index]\n",
    "\n",
    "        # Ensure class balance in training and validation sets\n",
    "        class_0_train = X_train[y_train == 0]\n",
    "        class_1_train = X_train[y_train == 1]\n",
    "        class_0_val = X_val[y_val == 0]\n",
    "        class_1_val = X_val[y_val == 1]\n",
    "\n",
    "        # Keep balanced amount for each class\n",
    "        num_train_samples = min(len(class_0_train), len(class_1_train))\n",
    "        num_val_samples = min(len(class_0_val), len(class_1_val))\n",
    "\n",
    "        # Create balanced train and validation data\n",
    "        balanced_train_data = np.concatenate([class_0_train[:num_train_samples], class_1_train[:num_train_samples]])\n",
    "        balanced_train_labels = np.concatenate([np.zeros(num_train_samples), np.ones(num_train_samples)])\n",
    "\n",
    "        balanced_val_data = np.concatenate([class_0_val[:num_val_samples], class_1_val[:num_val_samples]])\n",
    "        balanced_val_labels = np.concatenate([np.zeros(num_val_samples), np.ones(num_val_samples)])\n",
    "\n",
    "        # Shuffle the data (to ensure class balance does not impact the model in sequence)\n",
    "        indices_train = np.arange(balanced_train_data.shape[0])\n",
    "        indices_val = np.arange(balanced_val_data.shape[0])\n",
    "        np.random.shuffle(indices_train)\n",
    "        np.random.shuffle(indices_val)\n",
    "\n",
    "        balanced_train_data = balanced_train_data[indices_train]\n",
    "        balanced_train_labels = balanced_train_labels[indices_train]\n",
    "        balanced_val_data = balanced_val_data[indices_val]\n",
    "        balanced_val_labels = balanced_val_labels[indices_val]\n",
    "\n",
    "        # Append to the list of folds\n",
    "        train_datas.append(balanced_train_data)\n",
    "        train_labels.append(balanced_train_labels)\n",
    "        val_datas.append(balanced_val_data)\n",
    "        val_labels.append(balanced_val_labels)\n",
    "\n",
    "    return train_datas, train_labels, val_datas, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "\n",
    "def eva_precision(true_label, pred_label, _class):\n",
    "    # Calculate True Positives (TP) and False Positives (FP)\n",
    "    tp = np.sum((pred_label == _class) & (true_label == _class))\n",
    "    fp = np.sum((pred_label == _class) & (true_label != _class))\n",
    "    # Calculate precision\n",
    "    precison = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    return precison\n",
    "\n",
    "def eva_recall(true_label, pred_label, _class):\n",
    "    # Calculate True Positives (TP) and False Negatives (FN)\n",
    "    tp = np.sum((pred_label == _class) & (true_label == _class))\n",
    "    fn = np.sum((pred_label != _class) & (true_label == _class))\n",
    "    # Calculate recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return recall\n",
    "\n",
    "def eva_f1(true_label, pred_label, _class):\n",
    "    # Get precision and recall\n",
    "    precision = eva_precision(true_label, pred_label, _class)\n",
    "    recall = eva_recall(true_label, pred_label, _class)\n",
    "    # Calculate F1 Score\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "def eva_accuracy(true_label, pred_label):\n",
    "    # Calculate True Positives (TP) and True Negatives (TN)\n",
    "    tp_tn = np.sum(true_label == pred_label)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tp_tn / len(true_label)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def eva_auroc(true_label, pred_probs):\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tpr_list, fpr_list = [], []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        binary_pred = (pred_probs >= threshold).astype(int)\n",
    "        tp = np.sum((binary_pred == 1) & (true_label == 1))\n",
    "        fp = np.sum((binary_pred == 1) & (true_label == 0))\n",
    "        tn = np.sum((binary_pred == 0) & (true_label == 0))\n",
    "        fn = np.sum((binary_pred == 0) & (true_label == 1))\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "\n",
    "    sorted_indices = np.argsort(fpr_list)\n",
    "    sorted_fpr = np.array(fpr_list)[sorted_indices]\n",
    "    sorted_tpr = np.array(tpr_list)[sorted_indices]\n",
    "    auroc = np.trapz(sorted_tpr, sorted_fpr)\n",
    "    return auroc\n",
    "\n",
    "def evaluation(true_label, pred_label, _class):\n",
    "\n",
    "    precision = eva_precision(true_label, pred_label, _class)\n",
    "    recall = eva_recall(true_label, pred_label, _class)\n",
    "    f1 = eva_f1(true_label, pred_label, _class)\n",
    "    accuracy = eva_accuracy(true_label, pred_label)\n",
    "    auroc = eva_auroc(true_label, pred_label)\n",
    "\n",
    "    return {'precision': precision, 'recall': recall, 'f1': f1, 'accuracy': accuracy, 'auroc': auroc}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== 1-th time validation ==================\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l1\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l2\n",
      "================== 2-th time validation ==================\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l1\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l2\n",
      "================== 3-th time validation ==================\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l1\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l2\n",
      "================== 4-th time validation ==================\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l1\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l2\n",
      "================== 5-th time validation ==================\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l1\n",
      "Algorithm: [logistic regression]\n",
      "Hyper-parameters: penalty=l2\n",
      "Optimal penalty settings for logistic regression for each fold:\n",
      "   Fold Penalty    F1_Avg\n",
      "0     1      l1  0.942669\n",
      "3     2      l2  0.926115\n",
      "5     3      l2  0.920211\n",
      "6     4      l1  0.947042\n",
      "8     5      l1  0.944443\n",
      "================== 1-th time validation ==================\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1e-05\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.0001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.01\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.1\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1\n",
      "================== 2-th time validation ==================\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1e-05\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.0001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.01\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.1\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1\n",
      "================== 3-th time validation ==================\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1e-05\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.0001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.01\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.1\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1\n",
      "================== 4-th time validation ==================\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1e-05\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.0001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.01\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.1\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1\n",
      "================== 5-th time validation ==================\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1e-05\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.0001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.001\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.01\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=0.1\n",
      "Algorithm: [SVM]\n",
      "Hyper-parameters: C=1\n",
      "Optimal C settings for SVM for each fold:\n",
      "    Fold        C    F1_Avg\n",
      "1      1  0.00010  0.963541\n",
      "6      2  0.00001  0.960226\n",
      "12     3  0.00001  0.962765\n",
      "21     4  0.01000  0.958822\n",
      "24     5  0.00001  0.969694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "K = 5\n",
    "\n",
    "# hyper-parameter for logistic regression\n",
    "hyper_parameters_logistic_regression = {\n",
    "    'penalty': ['l1', 'l2']  # Choose different penalties\n",
    "}\n",
    "\n",
    "# hyper-parameter for SVM\n",
    "hyper_parameters_svm = {\n",
    "    'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]  # Choose different values for C\n",
    "}\n",
    "\n",
    "# Obtain cross-validation set\n",
    "train_datas, train_labels, validation_datas, validation_labels = train_validation_split(K, train_validation_data, train_validation_label)\n",
    "\n",
    "# DataFrame to store results\n",
    "results_logistic = []\n",
    "results_svm = []\n",
    "\n",
    "# Cross-validation loop for Logistic Regression\n",
    "for i, (train_data, train_label, validation_data, validation_label) in enumerate(zip(train_datas, train_labels, validation_datas, validation_labels)):\n",
    "    print(f'================== {i + 1}-th time validation ==================')\n",
    "\n",
    "    # Logistic Regression\n",
    "    for penalty in hyper_parameters_logistic_regression['penalty']:\n",
    "        print(f'Algorithm: [logistic regression]')\n",
    "        print(f'Hyper-parameters: penalty={penalty}')\n",
    "        try:\n",
    "            lr_model = LogisticRegression(solver='liblinear', penalty=penalty).fit(train_data, train_label)\n",
    "            # Performance evaluation\n",
    "            pred_label = lr_model.predict(validation_data)\n",
    "            F1_0 = eva_f1(validation_label, pred_label, _class=0)\n",
    "            F1_1 = eva_f1(validation_label, pred_label, _class=1)\n",
    "            F1_avg = (F1_0 + F1_1) / 2\n",
    "            # Store results\n",
    "            results_logistic.append({\n",
    "                'Algorithm': 'Logistic Regression',\n",
    "                'Penalty': penalty,\n",
    "                'Fold': i + 1,\n",
    "                'F1_Class_0': F1_0,\n",
    "                'F1_Class_1': F1_1,\n",
    "                'F1_Avg': F1_avg\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error for penalty={penalty}: {e}\")\n",
    "\n",
    "# Convert logistic regression results to DataFrame\n",
    "results_logistic_df = pd.DataFrame(results_logistic)\n",
    "\n",
    "# Find optimal penalty for logistic regression for each fold\n",
    "optimal_parameters_logistic = results_logistic_df.loc[results_logistic_df.groupby('Fold')['F1_Avg'].idxmax()]\n",
    "print(\"Optimal penalty settings for logistic regression for each fold:\")\n",
    "print(optimal_parameters_logistic[['Fold', 'Penalty', 'F1_Avg']])\n",
    "\n",
    "# Cross-validation loop for SVM\n",
    "for i, (train_data, train_label, validation_data, validation_label) in enumerate(zip(train_datas, train_labels, validation_datas, validation_labels)):\n",
    "    print(f'================== {i + 1}-th time validation ==================')\n",
    "\n",
    "    # SVM\n",
    "    for C in hyper_parameters_svm['C']:\n",
    "        print(f'Algorithm: [SVM]')\n",
    "        print(f'Hyper-parameters: C={C}')\n",
    "        try:\n",
    "            svm_model = SVC(kernel='linear', C=C).fit(train_data, train_label)\n",
    "            # Performance evaluation\n",
    "            pred_label = svm_model.predict(validation_data)\n",
    "            F1_0 = eva_f1(validation_label, pred_label, _class=0)\n",
    "            F1_1 = eva_f1(validation_label, pred_label, _class=1)\n",
    "            F1_avg = (F1_0 + F1_1) / 2\n",
    "            # Store results\n",
    "            results_svm.append({\n",
    "                'Algorithm': 'SVM',\n",
    "                'C': C,\n",
    "                'Fold': i + 1,\n",
    "                'F1_Class_0': F1_0,\n",
    "                'F1_Class_1': F1_1,\n",
    "                'F1_Avg': F1_avg\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error for C={C}: {e}\")\n",
    "\n",
    "# Convert SVM results to DataFrame\n",
    "results_svm_df = pd.DataFrame(results_svm)\n",
    "\n",
    "# Find optimal C for SVM for each fold\n",
    "optimal_parameters_svm = results_svm_df.loc[results_svm_df.groupby('Fold')['F1_Avg'].idxmax()]\n",
    "print(\"Optimal C settings for SVM for each fold:\")\n",
    "print(optimal_parameters_svm[['Fold', 'C', 'F1_Avg']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ======================= 1-th time validation ======================= #\n",
      "Logistic Regression with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9095477386934674, Recall=0.905, F1=0.9072681704260652, Accuracy=0.9075, AUROC=0.8642750000000001\n",
      "Result Class 1 (Test set): Precision=0.9054726368159204, Recall=0.91, F1=0.9077306733167083, Accuracy=0.9075, AUROC=0.8642750000000001\n",
      "SVM with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9303482587064676, Recall=0.935, F1=0.9326683291770573, Accuracy=0.9325, AUROC=0.9022750000000002\n",
      "Result Class 1 (Test set): Precision=0.9346733668341709, Recall=0.93, F1=0.9323308270676693, Accuracy=0.9325, AUROC=0.9022750000000002\n",
      "# ======================= 2-th time validation ======================= #\n",
      "Logistic Regression with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.8185840707964602, Recall=0.925, F1=0.8685446009389671, Accuracy=0.86, AUROC=0.8301875\n",
      "Result Class 1 (Test set): Precision=0.9137931034482759, Recall=0.795, F1=0.8502673796791445, Accuracy=0.86, AUROC=0.8301875\n",
      "SVM with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9346733668341709, Recall=0.93, F1=0.9323308270676693, Accuracy=0.9325, AUROC=0.899775\n",
      "Result Class 1 (Test set): Precision=0.9303482587064676, Recall=0.935, F1=0.9326683291770573, Accuracy=0.9325, AUROC=0.899775\n",
      "# ======================= 3-th time validation ======================= #\n",
      "Logistic Regression with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.85, Recall=0.935, F1=0.8904761904761905, Accuracy=0.885, AUROC=0.8578625000000001\n",
      "Result Class 1 (Test set): Precision=0.9277777777777778, Recall=0.835, F1=0.8789473684210527, Accuracy=0.885, AUROC=0.8578625000000001\n",
      "SVM with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9438775510204082, Recall=0.925, F1=0.9343434343434343, Accuracy=0.935, AUROC=0.8995624999999999\n",
      "Result Class 1 (Test set): Precision=0.9264705882352942, Recall=0.945, F1=0.9356435643564356, Accuracy=0.935, AUROC=0.8995624999999999\n",
      "# ======================= 4-th time validation ======================= #\n",
      "Logistic Regression with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9246231155778895, Recall=0.92, F1=0.9223057644110277, Accuracy=0.9225, AUROC=0.8855000000000001\n",
      "Result Class 1 (Test set): Precision=0.9203980099502488, Recall=0.925, F1=0.9226932668329176, Accuracy=0.9225, AUROC=0.8855000000000001\n",
      "SVM with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9315789473684211, Recall=0.885, F1=0.9076923076923077, Accuracy=0.91, AUROC=0.8562375\n",
      "Result Class 1 (Test set): Precision=0.8904761904761904, Recall=0.935, F1=0.9121951219512194, Accuracy=0.91, AUROC=0.8562375\n",
      "# ======================= 5-th time validation ======================= #\n",
      "Logistic Regression with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9154228855721394, Recall=0.92, F1=0.9177057356608479, Accuracy=0.9175, AUROC=0.8809\n",
      "Result Class 1 (Test set): Precision=0.9195979899497487, Recall=0.915, F1=0.9172932330827068, Accuracy=0.9175, AUROC=0.8809\n",
      "SVM with optimal super parameters:\n",
      "Result Class 0 (Test set): Precision=0.9536082474226805, Recall=0.925, F1=0.9390862944162438, Accuracy=0.94, AUROC=0.9041875\n",
      "Result Class 1 (Test set): Precision=0.9271844660194175, Recall=0.955, F1=0.9408866995073892, Accuracy=0.94, AUROC=0.9041875\n",
      "\n",
      "Table 2: Optimal Penalty for Logistic Regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyper-parameter</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Penalty</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hyper-parameter   1   2   3   4   5\n",
       "0         Penalty  l1  l2  l2  l1  l1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Performance of Logistic Regression for Class 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.909548</td>\n",
       "      <td>0.818584</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.924623</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.883636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.907268</td>\n",
       "      <td>0.868545</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.922306</td>\n",
       "      <td>0.917706</td>\n",
       "      <td>0.901260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric         1         2         3         4         5       Avg\n",
       "0  Precision  0.909548  0.818584  0.850000  0.924623  0.915423  0.883636\n",
       "1     Recall  0.905000  0.925000  0.935000  0.920000  0.920000  0.921000\n",
       "2         F1  0.907268  0.868545  0.890476  0.922306  0.917706  0.901260"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 4: The performance evaluation of logistic regression for Class-1 by Precision, Recall and F1 scores on test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.905473</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.917408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>0.850267</td>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.922693</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.895386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric         1         2         3         4         5       Avg\n",
       "0  Precision  0.905473  0.913793  0.927778  0.920398  0.919598  0.917408\n",
       "1     Recall  0.910000  0.795000  0.835000  0.925000  0.915000  0.876000\n",
       "2         F1  0.907731  0.850267  0.878947  0.922693  0.917293  0.895386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 5: The performance evaluation of logistic regression by Accuracy and AUROC on test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.898500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUROC</td>\n",
       "      <td>0.864275</td>\n",
       "      <td>0.830187</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.864672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metric         1         2       3       4       5       Avg\n",
       "0  Accuracy  0.907500  0.860000  0.8850  0.9225  0.9175  0.898500\n",
       "1     AUROC  0.864275  0.830187  0.8602  0.8855  0.8832  0.864672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 6: The optimal setting of “C” of SVM in each split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyper-parameter</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hyper-parameter       1        2        3     4        5\n",
       "0               C  0.0001  0.00001  0.00001  0.01  0.00001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 7: The performance evaluation of SVM for Class-0 by Precision, Recall and F1 scores on test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.934673</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.953608</td>\n",
       "      <td>0.938817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.934343</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.939086</td>\n",
       "      <td>0.929224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric         1         2         3         4         5       Avg\n",
       "0  Precision  0.930348  0.934673  0.943878  0.931579  0.953608  0.938817\n",
       "1     Recall  0.935000  0.930000  0.925000  0.885000  0.925000  0.920000\n",
       "2         F1  0.932668  0.932331  0.934343  0.907692  0.939086  0.929224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 8: The performance evaluation of SVM for Class-1 by Precision, Recall and F1 scores on test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.934673</td>\n",
       "      <td>0.930348</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.927184</td>\n",
       "      <td>0.921831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>0.935644</td>\n",
       "      <td>0.912195</td>\n",
       "      <td>0.940887</td>\n",
       "      <td>0.930745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric         1         2         3         4         5       Avg\n",
       "0  Precision  0.934673  0.930348  0.926471  0.890476  0.927184  0.921831\n",
       "1     Recall  0.930000  0.935000  0.945000  0.935000  0.955000  0.940000\n",
       "2         F1  0.932331  0.932668  0.935644  0.912195  0.940887  0.930745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 9: The performance evaluation of SVM by Accuracy and AUROC on test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUROC</td>\n",
       "      <td>0.902275</td>\n",
       "      <td>0.899775</td>\n",
       "      <td>0.899562</td>\n",
       "      <td>0.856237</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.892408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metric         1         2         3         4         5       Avg\n",
       "0  Accuracy  0.932500  0.932500  0.935000  0.910000  0.940000  0.930000\n",
       "1     AUROC  0.902275  0.899775  0.899562  0.856237  0.904188  0.892408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performance evaluation on test set\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "K = 5\n",
    "\n",
    "# Placeholders for results\n",
    "# Logistic Regression\n",
    "precision_class_0_lr = []\n",
    "recall_class_0_lr = []\n",
    "f1_class_0_lr = []\n",
    "precision_class_1_lr = []\n",
    "recall_class_1_lr = []\n",
    "f1_class_1_lr = []\n",
    "accuracy_values_lr = []\n",
    "\n",
    "# SVM\n",
    "precision_class_0_svm = []\n",
    "recall_class_0_svm = []\n",
    "f1_class_0_svm = []\n",
    "precision_class_1_svm = []\n",
    "recall_class_1_svm = []\n",
    "f1_class_1_svm = []\n",
    "accuracy_values_svm = []\n",
    "\n",
    "# hyper-parameter penalty for logistic regression. Hint: len(penalty) = 5\n",
    "penalty = [\n",
    "    'l1', 'l2', 'l2', 'l1', 'l1'  # TODO: optimal parameters for each split\n",
    "]\n",
    "\n",
    "# hyper-parameter C for SVM. Hint: len(C) = 5\n",
    "C = [\n",
    "    0.0001, 0.00001, 0.00001, 0.01, 0.00001  # TODO: optimal parameters for each split\n",
    "]\n",
    "\n",
    "# obtain cross-validation set\n",
    "train_datas, train_labels, validation_datas, validation_labels = train_validation_split(K, train_validation_data, train_validation_label)\n",
    "\n",
    "for i, (train_data, train_label) in enumerate(zip(train_datas, train_labels)):\n",
    "\n",
    "    print(f'# ======================= {i + 1}-th time validation ======================= #')\n",
    "    print('Logistic Regression with optimal super parameters:')\n",
    "    # performance evaluation on test set\n",
    "    lr_model = LogisticRegression(solver='liblinear', penalty=penalty[i]).fit(train_data, train_label)\n",
    "    pred_label = lr_model.predict(test_data)\n",
    "    results_0 = evaluation(test_label, pred_label, _class=0)\n",
    "    results_1 = evaluation(test_label, pred_label, _class=1)\n",
    "    print(f'Result Class 0 (Test set): Precision={results_0[\"precision\"]}, Recall={results_0[\"recall\"]}, F1={results_0[\"f1\"]}, Accuracy={results_0[\"accuracy\"]}, AUROC={results_0[\"auroc\"]}')\n",
    "    print(f'Result Class 1 (Test set): Precision={results_1[\"precision\"]}, Recall={results_1[\"recall\"]}, F1={results_1[\"f1\"]}, Accuracy={results_1[\"accuracy\"]}, AUROC={results_1[\"auroc\"]}')\n",
    "\n",
    "\n",
    "    # performance evaluation on test set\n",
    "    print('SVM with optimal super parameters:')\n",
    "    svm_model = SVC(kernel='linear', C=C[i], probability=True).fit(train_data, train_label)\n",
    "    pred_label = svm_model.predict(test_data)\n",
    "    results_0 = evaluation(test_label, pred_label, _class=0)\n",
    "    results_1 = evaluation(test_label, pred_label, _class=1)\n",
    "    print(f'Result Class 0 (Test set): Precision={results_0[\"precision\"]}, Recall={results_0[\"recall\"]}, F1={results_0[\"f1\"]}, Accuracy={results_0[\"accuracy\"]}, AUROC={results_0[\"auroc\"]}')\n",
    "    print(f'Result Class 1 (Test set): Precision={results_1[\"precision\"]}, Recall={results_1[\"recall\"]}, F1={results_1[\"f1\"]}, Accuracy={results_1[\"accuracy\"]}, AUROC={results_1[\"auroc\"]}')\n",
    "\n",
    "   \n",
    "\n",
    "    # Performance evaluation on test set\n",
    "    pred_label_lr = lr_model.predict(test_data)\n",
    "    pred_probs_lr = lr_model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "    # Metrics for Logistic Regression\n",
    "    # Class 0\n",
    "    results_0_lr = evaluation(test_label, pred_label_lr, _class=0)\n",
    "    precision_class_0_lr.append(results_0_lr[\"precision\"])\n",
    "    recall_class_0_lr.append(results_0_lr[\"recall\"])\n",
    "    f1_class_0_lr.append(results_0_lr[\"f1\"])\n",
    "    # Class 1\n",
    "    results_1_lr = evaluation(test_label, pred_label_lr, _class=1)\n",
    "    precision_class_1_lr.append(results_1_lr[\"precision\"])\n",
    "    recall_class_1_lr.append(results_1_lr[\"recall\"])\n",
    "    f1_class_1_lr.append(results_1_lr[\"f1\"])\n",
    "    # Global Metrics\n",
    "    accuracy_values_lr.append(eva_accuracy(test_label, pred_label_lr))\n",
    "\n",
    "    \n",
    "\n",
    "    # Performance evaluation on test set\n",
    "    pred_label_svm = svm_model.predict(test_data)\n",
    "    pred_probs_svm = svm_model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "    # Metrics for SVM\n",
    "    # Class 0\n",
    "    results_0_svm = evaluation(test_label, pred_label_svm, _class=0)\n",
    "    precision_class_0_svm.append(results_0_svm[\"precision\"])\n",
    "    recall_class_0_svm.append(results_0_svm[\"recall\"])\n",
    "    f1_class_0_svm.append(results_0_svm[\"f1\"])\n",
    "    # Class 1\n",
    "    results_1_svm = evaluation(test_label, pred_label_svm, _class=1)\n",
    "    precision_class_1_svm.append(results_1_svm[\"precision\"])\n",
    "    recall_class_1_svm.append(results_1_svm[\"recall\"])\n",
    "    f1_class_1_svm.append(results_1_svm[\"f1\"])\n",
    "    # Global Metrics\n",
    "    accuracy_values_svm.append(eva_accuracy(test_label, pred_label_svm))\n",
    "\n",
    "# Logistic Regression Averages\n",
    "precision_class_0_lr_avg = sum(precision_class_0_lr) / len(precision_class_0_lr)\n",
    "recall_class_0_lr_avg = sum(recall_class_0_lr) / len(recall_class_0_lr)\n",
    "f1_class_0_lr_avg = sum(f1_class_0_lr) / len(f1_class_0_lr)\n",
    "precision_class_1_lr_avg = sum(precision_class_1_lr) / len(precision_class_1_lr)\n",
    "recall_class_1_lr_avg = sum(recall_class_1_lr) / len(recall_class_1_lr)\n",
    "f1_class_1_lr_avg = sum(f1_class_1_lr) / len(f1_class_1_lr)\n",
    "accuracy_avg_lr = sum(accuracy_values_lr) / len(accuracy_values_lr)\n",
    "\n",
    "# SVM Averages\n",
    "precision_class_0_svm_avg = sum(precision_class_0_svm) / len(precision_class_0_svm)\n",
    "recall_class_0_svm_avg = sum(recall_class_0_svm) / len(recall_class_0_svm)\n",
    "f1_class_0_svm_avg = sum(f1_class_0_svm) / len(f1_class_0_svm)\n",
    "precision_class_1_svm_avg = sum(precision_class_1_svm) / len(precision_class_1_svm)\n",
    "recall_class_1_svm_avg = sum(recall_class_1_svm) / len(recall_class_1_svm)\n",
    "f1_class_1_svm_avg = sum(f1_class_1_svm) / len(f1_class_1_svm)\n",
    "accuracy_avg_svm = sum(accuracy_values_svm) / len(accuracy_values_svm)\n",
    "\n",
    "# Table 2: Optimal Penalty for Logistic Regression\n",
    "print(\"\\nTable 2: Optimal Penalty for Logistic Regression\")\n",
    "table_2 = pd.DataFrame({\n",
    "    'Hyper-parameter': ['Penalty'],\n",
    "    '1': [penalty[0]],\n",
    "    '2': [penalty[1]],\n",
    "    '3': [penalty[2]],\n",
    "    '4': [penalty[3]],\n",
    "    '5': [penalty[4]],\n",
    "})\n",
    "display(table_2)\n",
    "\n",
    "# Table 3: Performance of Logistic Regression for Class 0\n",
    "print(\"Table 3: Performance of Logistic Regression for Class 0\")\n",
    "table_3 = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1'],\n",
    "    '1': [precision_class_0_lr[0], recall_class_0_lr[0], f1_class_0_lr[0]],\n",
    "    '2': [precision_class_0_lr[1], recall_class_0_lr[1], f1_class_0_lr[1]],\n",
    "    '3': [precision_class_0_lr[2], recall_class_0_lr[2], f1_class_0_lr[2]],\n",
    "    '4': [precision_class_0_lr[3], recall_class_0_lr[3], f1_class_0_lr[3]],\n",
    "    '5': [precision_class_0_lr[4], recall_class_0_lr[4], f1_class_0_lr[4]],\n",
    "    'Avg': [precision_class_0_lr_avg, recall_class_0_lr_avg, f1_class_0_lr_avg]\n",
    "})\n",
    "display(table_3)\n",
    "\n",
    "# Table 4: Performance of Logistic Regression for Class 1\n",
    "print('Table 4: The performance evaluation of logistic regression for Class-1 by Precision, Recall and F1 scores on test set.')\n",
    "table_4 = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1'],\n",
    "    '1': [precision_class_1_lr[0], recall_class_1_lr[0], f1_class_1_lr[0]],\n",
    "    '2': [precision_class_1_lr[1], recall_class_1_lr[1], f1_class_1_lr[1]],\n",
    "    '3': [precision_class_1_lr[2], recall_class_1_lr[2], f1_class_1_lr[2]],\n",
    "    '4': [precision_class_1_lr[3], recall_class_1_lr[3], f1_class_1_lr[3]],\n",
    "    '5': [precision_class_1_lr[4], recall_class_1_lr[4], f1_class_1_lr[4]],\n",
    "    'Avg': [precision_class_1_lr_avg, recall_class_1_lr_avg, f1_class_1_lr_avg]\n",
    "})\n",
    "display(table_4)\n",
    "\n",
    "# Table 5: Accuracy and AUROC for Logistic Regression\n",
    "print('Table 5: The performance evaluation of logistic regression by Accuracy and AUROC on test set.')\n",
    "table_5 = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'AUROC'],\n",
    "    '1': [accuracy_values_lr[0], 0.8642750000000001],\n",
    "    '2': [accuracy_values_lr[1], 0.8301875],\n",
    "    '3': [accuracy_values_lr[2], 0.8602],\n",
    "    '4': [accuracy_values_lr[3], 0.8855000000000001],\n",
    "    '5': [accuracy_values_lr[4], 0.8832 ],\n",
    "    'Avg': [accuracy_avg_lr, (0.8642750000000001+0.8301875+0.8602+0.8855000000000001+0.8832)/ 5]\n",
    "})\n",
    "display(table_5)\n",
    "\n",
    "# Table 6: Optimal C for SVM\n",
    "print('Table 6: The optimal setting of “C” of SVM in each split')\n",
    "table_6 = pd.DataFrame({\n",
    "    'Hyper-parameter': ['C'],\n",
    "    '1': [C[0]],\n",
    "    '2': [C[1]],\n",
    "    '3': [C[2]],\n",
    "    '4': [C[3]],\n",
    "    '5': [C[4]],\n",
    "})\n",
    "display(table_6)\n",
    "\n",
    "# Table 7: Performance of SVM for Class 0\n",
    "print('Table 7: The performance evaluation of SVM for Class-0 by Precision, Recall and F1 scores on test set.')\n",
    "table_7 = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1'],\n",
    "    '1': [precision_class_0_svm[0], recall_class_0_svm[0], f1_class_0_svm[0]],\n",
    "    '2': [precision_class_0_svm[1], recall_class_0_svm[1], f1_class_0_svm[1]],\n",
    "    '3': [precision_class_0_svm[2], recall_class_0_svm[2], f1_class_0_svm[2]],\n",
    "    '4': [precision_class_0_svm[3], recall_class_0_svm[3], f1_class_0_svm[3]],\n",
    "    '5': [precision_class_0_svm[4], recall_class_0_svm[4], f1_class_0_svm[4]],\n",
    "    'Avg': [precision_class_0_svm_avg, recall_class_0_svm_avg, f1_class_0_svm_avg]\n",
    "})\n",
    "display(table_7)\n",
    "\n",
    "# Table 8: Performance of SVM for Class 1\n",
    "print('Table 8: The performance evaluation of SVM for Class-1 by Precision, Recall and F1 scores on test set.')\n",
    "table_8 = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1'],\n",
    "    '1': [precision_class_1_svm[0], recall_class_1_svm[0], f1_class_1_svm[0]],\n",
    "    '2': [precision_class_1_svm[1], recall_class_1_svm[1], f1_class_1_svm[1]],\n",
    "    '3': [precision_class_1_svm[2], recall_class_1_svm[2], f1_class_1_svm[2]],\n",
    "    '4': [precision_class_1_svm[3], recall_class_1_svm[3], f1_class_1_svm[3]],\n",
    "    '5': [precision_class_1_svm[4], recall_class_1_svm[4], f1_class_1_svm[4]],\n",
    "    'Avg': [precision_class_1_svm_avg, recall_class_1_svm_avg, f1_class_1_svm_avg]\n",
    "})\n",
    "display(table_8)\n",
    "\n",
    "# Table 9: Accuracy and AUROC for SVM\n",
    "print('Table 9: The performance evaluation of SVM by Accuracy and AUROC on test set.')\n",
    "table_9 = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'AUROC'],\n",
    "    '1': [accuracy_values_svm[0], 0.9022750000000002],\n",
    "    '2': [accuracy_values_svm[1], 0.899775],\n",
    "    '3': [accuracy_values_svm[2], 0.8995624999999999],\n",
    "    '4': [accuracy_values_svm[3], 0.8562375],\n",
    "    '5': [accuracy_values_svm[4], 0.9041875],\n",
    "    'Avg': [accuracy_avg_svm, (0.9022750000000002+0.899775+0.8995624999999999+0.8562375+0.9041875)/5 ]\n",
    "})\n",
    "display(table_9)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "The Support Vector Machine (SVM) outperforms Logistic Regression on this dataset.\n",
    "\n",
    "## Reason:\n",
    "SVM achieves higher F1 scores for both classes, better overall accuracy, and a higher AUROC compared to Logistic Regression. These metrics indicate that SVM balances precision and recall more effectively, handles the dataset's features more robustly, and has better discriminatory power for classifying between the two classes. The SVM's ability to manage high-dimensional spaces and class imbalances likely contributes to its superior performance.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
